[
  {
    "objectID": "tutorials/02_neon_reflectance_weather_qa.html",
    "href": "tutorials/02_neon_reflectance_weather_qa.html",
    "title": "Reflectance pre-processing: masking out bad weather data in GEE",
    "section": "",
    "text": "Since reflectance data is generated from a passive energy source (the sun), data collected in cloudy sky conditions are not directly comparable to data collected in clear-sky conditions, as overhead clouds can obscure the incoming light source. AOP aims to collect data only in optimal (&lt;10% cloud-cover) weather conditions, but cannot always do so due to logistical constraints. The flight operators record the weather conditions during each flight, and this information is passed through to the final data product at the level of the flight line (as cloud conditions can change throughout the day). Cloud conditions are reported as green (&lt;10% cloud cover), yellow (10-50% cloud cover), or red (&gt;50% cloud cover). The figure below shows some examples of what the cloud conditions look like at different flights collected in the three different weather classes (green, yellow, and red).\nNote that there is an important distinction between airborne and satellite reflectance data. Satellite data is collected in all weather conditions, and the clouds are below the sensor, so algorithms can be generated to filter out cloudy pixels. With aerial data, we have more control over when the data are collected, to a degree. However, clouds may be present overhead, if it were deemed necessary to collect in sub-optimal weather conditions. AOP typically will only collect in “red” sky conditions if we are running out of time in a Domain and the weather isn’t forecasted to improve. Since the clouds won’t appear in the actual data, maintaining this record of cloud conditions is essential for properly understanding the data, and using it for change detection or other research applications. For a more direct comparison of reflectance values, we recommend only working with the clear-weather data. This lesson outlines how to do this in GEE.",
    "crumbs": [
      "Tutorials",
      "2 Reflectance Weather and QA Considerations"
    ]
  },
  {
    "objectID": "tutorials/02_neon_reflectance_weather_qa.html#objectives",
    "href": "tutorials/02_neon_reflectance_weather_qa.html#objectives",
    "title": "Reflectance pre-processing: masking out bad weather data in GEE",
    "section": "Objectives",
    "text": "Objectives\nAfter completing this activity, you will be able to: - Extract and plot the weather quality indicator band from the Surface Directional Reflectance dataset - Mask reflectance data to pull out only clear-weather data for a given site - Explore other QA bands included in the Reflectance data set",
    "crumbs": [
      "Tutorials",
      "2 Reflectance Weather and QA Considerations"
    ]
  },
  {
    "objectID": "tutorials/02_neon_reflectance_weather_qa.html#requirements",
    "href": "tutorials/02_neon_reflectance_weather_qa.html#requirements",
    "title": "Reflectance pre-processing: masking out bad weather data in GEE",
    "section": "Requirements",
    "text": "Requirements\n\nComplete the following introductory AOP GEE tutorials:\n\nIntroduction to AOP Public Datasets in Google Earth Engine (GEE)\n\nAn understanding of hyperspectral data and AOP spectral data products. If this is your first time working with AOP hyperspectral data, we encourage you to start with:\n\nIntro to Working with Hyperspectral Remote Sensing Data in R. You do not need to follow along with the code in those lessons, but at least read through to gain a better understanding of NEON’s hyperspectral data product.",
    "crumbs": [
      "Tutorials",
      "2 Reflectance Weather and QA Considerations"
    ]
  },
  {
    "objectID": "tutorials/02_neon_reflectance_weather_qa.html#read-in-the-aop-surface-directional-reflectance-2019-dataset-at-soap",
    "href": "tutorials/02_neon_reflectance_weather_qa.html#read-in-the-aop-surface-directional-reflectance-2019-dataset-at-soap",
    "title": "Reflectance pre-processing: masking out bad weather data in GEE",
    "section": "Read in the AOP Surface Directional Reflectance 2019 Dataset at SOAP",
    "text": "Read in the AOP Surface Directional Reflectance 2019 Dataset at SOAP\nFor this exercise, we will read in directional reflectance data from the NEON site Soaproot Saddle (SOAP) collected in 2019:\n// Filter image collection by date and site to pull out a single image\nvar soapSDR = ee.ImageCollection(\"projects/neon-prod-earthengine/assets/HSI_REFL/001\")\n  .filterDate('2019-01-01', '2019-12-31')\n  .filterMetadata('NEON_SITE', 'equals', 'SOAP')\n  .first();",
    "crumbs": [
      "Tutorials",
      "2 Reflectance Weather and QA Considerations"
    ]
  },
  {
    "objectID": "tutorials/02_neon_reflectance_weather_qa.html#display-the-qa-bands",
    "href": "tutorials/02_neon_reflectance_weather_qa.html#display-the-qa-bands",
    "title": "Reflectance pre-processing: masking out bad weather data in GEE",
    "section": "Display the QA Bands",
    "text": "Display the QA Bands\nFrom the previous lesson, recall that the reflectance images include 442 bands. Bands 0-425 are the data bands, which store the spectral reflectance values for each wavelength recorded by the NEON Imaging Spectrometer (NIS). The remaining bands (426-441) contain metadata and QA information that are important for understanding and properly interpreting the hyperspectral data. The data bands all follow the naming convention B001, B002, …, B426, and the QA bands have more descriptive names that start with something other than the letter “B”, so we can use that information to extract the QA bands.\n// Pull out and display only the qa bands (these all start with something other than B)\n// '[^B].*' is a regular expression to pull out bands that don't start with B\nvar soapSDR_qa = soapSDR.select('[^B].*') \nprint('QA Bands',soapSDR_qa)\n\n  \n\nMost of these QA bands are inputs to and outputs from the Atmospheric Correction (ATCOR), the process which converts radiance to atmospherically corrected reflectance. We will elaborate on these QA bands further, and encourage you to read more details about these data in the NEON Imaging Spectrometer Radiance to Reflectance Algorithm Theoritical Basis Document. For the purposes of this exercise, we will focus on the Weather Quality Indicator band. Note that you can explore each of the QA bands, following similar steps below, adjusting the band names and values accordingly.",
    "crumbs": [
      "Tutorials",
      "2 Reflectance Weather and QA Considerations"
    ]
  },
  {
    "objectID": "tutorials/02_neon_reflectance_weather_qa.html#read-in-the-weather_quality_indicator-band",
    "href": "tutorials/02_neon_reflectance_weather_qa.html#read-in-the-weather_quality_indicator-band",
    "title": "Reflectance pre-processing: masking out bad weather data in GEE",
    "section": "Read in the Weather_Quality_Indicator Band",
    "text": "Read in the Weather_Quality_Indicator Band\nThe weather information, called Weather_Quality_Indicator is one of the most important pieces of QA information that is collected about the NIS data, as it has a direct impact on the reflectance values.\nThese next lines of code pull out the Weather_Quality_Indicator band, select the “green” weather data from that band, and apply a mask to keep only the clear-weather data, which is saved to the variable soapSDR_clear.\n// Extract a single band Weather Quality QA layer\nvar soapWeather = soapSDR.select(['Weather_Quality_Indicator']);\n\n// Select only the clear weather data (&lt;10% cloud cover)\nvar soapClearWeather = soapWeather.eq(1); // 1 = 0-10% cloud cover\n\n// Mask out all cloudy pixels from the SDR image\nvar soapSDR_clear = soapSDR.updateMask(soapClearWeather);",
    "crumbs": [
      "Tutorials",
      "2 Reflectance Weather and QA Considerations"
    ]
  },
  {
    "objectID": "tutorials/02_neon_reflectance_weather_qa.html#plot-the-weather-quality-band-data",
    "href": "tutorials/02_neon_reflectance_weather_qa.html#plot-the-weather-quality-band-data",
    "title": "Reflectance pre-processing: masking out bad weather data in GEE",
    "section": "Plot the weather quality band data",
    "text": "Plot the weather quality band data\nFor reference, we can plot the weather band data, using AOP’s stop-light (red/yellow/green) color scheme, with the code below:\n\n// center the map at the lat / lon of the site, set zoom to 12\nMap.setCenter(-119.25, 37.06, 11);\n\n// Define a palette for the weather - to match NEON AOP's weather color conventions\nvar gyrPalette = [\n  '00ff00', // green (&lt;10% cloud cover)\n  'ffff00', // yellow (10-50% cloud cover)\n  'ff0000' // red (&gt;50% cloud cover)\n];\n\n// Display the weather band (cloud conditions) with the green-yellow-red palette\nMap.addLayer(soapWeather,\n             {min: 1, max: 3, palette: gyrPalette, opacity: 0.3},\n             'SOAP 2019 Cloud Cover Map');",
    "crumbs": [
      "Tutorials",
      "2 Reflectance Weather and QA Considerations"
    ]
  },
  {
    "objectID": "tutorials/02_neon_reflectance_weather_qa.html#plot-the-clear-weather-reflectance-data",
    "href": "tutorials/02_neon_reflectance_weather_qa.html#plot-the-clear-weather-reflectance-data",
    "title": "Reflectance pre-processing: masking out bad weather data in GEE",
    "section": "Plot the clear-weather reflectance data",
    "text": "Plot the clear-weather reflectance data\nFinally, we can plot a true-color image of only the clear-weather data, from soapSDR_clear that we created earlier:\n// Create a 3-band cloud-free image \nvar soapSDR_RGB = soapSDR_clear.select(['B053', 'B035', 'B019']);\n\n// Display the SDR image\nMap.addLayer(soapSDR_RGB, {min:103, max:1160}, 'SOAP 2019 Reflectance RGB');",
    "crumbs": [
      "Tutorials",
      "2 Reflectance Weather and QA Considerations"
    ]
  },
  {
    "objectID": "tutorials/02_neon_reflectance_weather_qa.html#plot-acquisition-dates",
    "href": "tutorials/02_neon_reflectance_weather_qa.html#plot-acquisition-dates",
    "title": "Reflectance pre-processing: masking out bad weather data in GEE",
    "section": "Plot acquisition dates",
    "text": "Plot acquisition dates\nWe can apply the same concepts to explore another one of the QA bands, this time let’s look at the Acquisition_Date. This may be useful if you are trying to find the dates that correspond to field data you’ve collected, or you want to scale up to satellite data, for example. To determine the minimum and maximum dates, you can use reduceRegion with the reducer ee.Reducer.minMax() as follows. Then use these start and end date values in the visualization parameters.\nTip: You may not wish to show every layer by default if you are plotting many layers. You can choose not to display a layer by default by including a “0” as the last input of Map.addLayer. Once you run the code, to toggle the layer on, find the Layers tab in the upper right corner of the Map Window and check the box to the left of the layer you want to display. You can click on the lock icon to make it so that the Layers full display stays open (by default it minimizes).\n// Extract acquisition dates QA band\nvar soapDates = soapSDR.select(['Acquisition_Date']);\n\n// Get the minimum and maximum values of the soapDates band\nvar minMaxValues = soapDates.reduceRegion({reducer: ee.Reducer.minMax(),maxPixels: 1e10})\nprint('min and max dates', minMaxValues);\n    \n// Map acquisition dates, don't display layer by default\nMap.addLayer(soapDates,\n            {min:20190612, max:20190616, opacity: 0.5},\n            'SOAP 2019 Acquisition Dates',0);",
    "crumbs": [
      "Tutorials",
      "2 Reflectance Weather and QA Considerations"
    ]
  },
  {
    "objectID": "tutorials/02_neon_reflectance_weather_qa.html#recap",
    "href": "tutorials/02_neon_reflectance_weather_qa.html#recap",
    "title": "Reflectance pre-processing: masking out bad weather data in GEE",
    "section": "Recap",
    "text": "Recap\nIn this lesson you learned how to read in Weather Quality Information from the Reflectance QA bands in GEE. You learned to mask data to keep only the imagery collected in the clearest sky conditions (&lt;10% cloud cover), and plot the three weather quality classes. You also learned how to find the other QA bands. Following a similar approach, you can explore each of the QA bands similarly. Filtering by the weather quality is an important first pre-processing step to working with NEON hyperspectral data, and is essential for interpreting the data and carrying out subsequent data analysis.",
    "crumbs": [
      "Tutorials",
      "2 Reflectance Weather and QA Considerations"
    ]
  },
  {
    "objectID": "tutorials/02_neon_reflectance_weather_qa.html#get-lesson-code",
    "href": "tutorials/02_neon_reflectance_weather_qa.html#get-lesson-code",
    "title": "Reflectance pre-processing: masking out bad weather data in GEE",
    "section": "Get Lesson Code",
    "text": "Get Lesson Code\nAOP GEE SDR Weather Quality",
    "crumbs": [
      "Tutorials",
      "2 Reflectance Weather and QA Considerations"
    ]
  },
  {
    "objectID": "setup/setup.html",
    "href": "setup/setup.html",
    "title": "Setup Instructions",
    "section": "",
    "text": "Setup Instructions\nTo follow along during the workshop, or to run through the tutorials contained within the repository using the Google Earth Engine Code Editor, the following steps are required.\n\nGoogle Earth Engine Account\n\nCreate a Noncommercial Google Earth Engine account (if you don’t already have one) at https://earthengine.google.com/noncommercial/\n\nGoogle Earth Engine Project\n\nOnce your EE account is set up, you will need to create a Google Cloud project. This is required to run the live-coding exercises. You can follow the instructions in the Google Earth Engine access guide to set up your project.\n\nLaptop or tablet\n\nFollowing along with the exercises requires a laptop or tablet.",
    "crumbs": [
      "Setup Instructions",
      "Setup"
    ]
  },
  {
    "objectID": "neon-aop-gee.html",
    "href": "neon-aop-gee.html",
    "title": "NEON Airborne Remote Sensing in GEE Tutorials",
    "section": "",
    "text": "Welcome to the NEON Airborne Remote Sensing in GEE Resources Repository! This repository provides tutorials to help the community work with AOP raster data products in Google Earth Engine. Data products are generated from NEON AOP’s Hypespectral, Lidar, and Camera sensors.\nIn the interest of open science, this repository has been made public, but is still under active development. Make sure to consult the change log for the most recent changes to the repository. Contributions from all parties are welcome.",
    "crumbs": [
      "Welcome",
      "Repository Description"
    ]
  },
  {
    "objectID": "neon-aop-gee.html#contact-info",
    "href": "neon-aop-gee.html#contact-info",
    "title": "NEON Airborne Remote Sensing in GEE Tutorials",
    "section": "Contact Info",
    "text": "Contact Info\nNEON AOP\nOrganization: National Ecological Observatory Network Airborne Observation Platform (NEON AOP)1\nWebsite: https://neonscience.org/\nContact: - https://www.neonscience.org/about/contact-us/\n- listaopgee@battelleecology.org\n1NEON is a project fully funded by the National Science Foundation and operated by Battelle.\nSpatial Bytes\nWebsite:\nContact:",
    "crumbs": [
      "Welcome",
      "Repository Description"
    ]
  },
  {
    "objectID": "CODE_OF_CONDUCT.html",
    "href": "CODE_OF_CONDUCT.html",
    "title": "NEON Code of Conduct",
    "section": "",
    "text": "NEON Code of Conduct\nThe National Ecological Observatory Network (NEON) welcomes contributions from everyone who shares our values of unity, creativity, collaboration, excellence, and appreciation. As such, we have adopted this Code of Conduct, including participation guidelines, and require all NEON community members to agree and adhere to them to help us create a safe and positive community experience for all. Here, we define the NEON community as anyone who participates in a NEON event and/or otherwise engages with the NEON program. These guidelines apply to Battelle staff and participants external to the NEON program. Battelle staff are also broadly bound to the Battelle Code of Business Ethics and Conduct.\n\nWhen and How to Use These Guidelines\nThese guidelines outline both expected and prohibited behaviors as members of the NEON community in all activities, both at in-person events (e.g., meetings, workshops, conferences) and online spaces (e.g., community forum, social media, virtual meetings and events). NEON event leaders are required to share this Code of Conduct and to ask participants to review and agree to it when they sign up for an event. Participation is contingent upon following these guidelines.\n\n\nExpected Behaviors\nOur community exists to advance science in a manner that is welcoming to all who participate in its processes. This requires that we actively practice kindness, empathy, and humility in all that we do while being mindful of the following expected behaviors.\n\n\nBe Respectful and Trustworthy\nBe attentive, listen, and fully engage in community activities. Value each other’s ideas, styles, and viewpoints. Address differences of opinion through respectful discourse. Be open to being wrong. Be direct, constructive, and positive. Be honest and avoid spreading misinformation. Take responsibility for your impact and your mistakes; if someone says they have been harmed through your words or actions, listen carefully, apologize sincerely, and correct the behavior going forward.\n\n\nBe Direct but Professional\nWe must provide space for giving and receiving constructive feedback to improve our processes. We are likely to have some discussions about if and when criticism is respectful and when it is not. We must be able to speak directly when we disagree and when we think we need to improve.\n\n\nBe Open and Welcoming\nMembers of the NEON community come from many perspectives and backgrounds. Be respectful of these differences and seek to understand them. Think of others’ needs from their points of view. Encourage all voices, help them to be heard, and listen actively. Provide alternative ways to contribute when possible. Respect people’s right to privacy and confidentiality. Be open to learning from and educating others as well as educating yourself.\n\n\nAcknowledge Contributions and Celebrate Achievements\nShare credit and give appreciation for contributions from the community. Collectively celebrate accomplishments and achievements that further advance the community’s vision and goals.\n\n\nCollaborate and Co-Create\nCollaborate across the community, actively seeking a breadth of perspectives to spark creativity and idea generation. Work with members of the NEON community to build strong relationships and trust and to co-create programs that are mutually beneficial.\n\n\nUnacceptable Behaviors\n\nPersonal Attacks\nConflicts will inevitably arise, but frustration should never turn into a verbal personal attack. It is not okay to insult, demean, or belittle others. Attacking someone or manipulating someone psychologically ( e.g. “gaslighting”) because of their opinions, beliefs, and ideas is not acceptable.\n\n\nDerogatory Language\nIt is not acceptable to use hurtful or harmful language. If you are unsure if a word is derogatory, do not use it.\n\n\nDisruptive Behavior\nSustained disruption of events, forums, or meetings, including talks and presentations, will not be tolerated. We will treat influencing or encouraging disruptive behavior and activities of others the same way we treat leading the activities themselves, and thus the same consequences apply.\n\n\nHarassment\nEveryone should be treated with respect and dignity. We are committed to providing an environment free of harassment. Harassment based on any characteristic protected under applicable federal, state, or local law is prohibited. Harassment can take many forms including belittling, bullying, or threatening verbal or physical conduct. We define sexual harassment as unwelcome sexual advances, requests for sexual favors, or other visual, verbal, or physical conduct of a sexual nature and when such conduct has the purpose or effect of unreasonably interfering with an individual’s participation with the NEON program or of creating an intimidating, hostile, or offensive environment. Unwelcome sexual attention or unwelcome physical contact or simulated contact is not acceptable.\n\n\nViolence and Threats of Violence\nWe prohibit and will not tolerate any form of violence committed by or against an employee, manager, or third-party, including vendors and visitors. Violence and threats of violence are not tolerated - online or offline. Anyone engaged in violent acts will be reported to the proper authorities.\n\n\n\nConsequences of Unacceptable Behavior\nUnacceptable behavior from any NEON community member will not be tolerated. Anyone asked to stop unacceptable behavior is expected to comply immediately. Violation of this Code of Conduct may result in being asked to leave an event or online space, either temporarily or for the duration of the event. Continued or severe infractions of this code may result in being banned from participation in future spaces, events, and activities in perpetuity.\nReports of harassment/discrimination will be promptly and thoroughly investigated and appropriate measures will be taken to address the situation. Illegal behavior will be reported to law enforcement.\n\n\nReporting a Violation of these Guidelines\nIf you experience sexual harassment or personal safety violations, first find a safe space, and report the violation immediately to the Battelle Ethics Hotline (855.296.2232) or online. For other violations of this Code of Conduct, please talk to a Battelle staff member. In the case of life-threatening and illegal activities, call 911.\n\n\nCommunity Feedback\nEveryone is encouraged to provide feedback on their experience with the NEON program. Your input is welcome through https://www.neonscience.org/about/contact-us.\n\n\nAcknowledgments\nThis Code of Conduct and participation guidelines were adapted from Mozilla’s Participation Guidelines with additional content adapted from OpenCon’s Code of Conduct. We thank all Battelle and NEON staff, the NEON Community Engagement Technical Working Group, and the NEON Science, Technology, and Education Advisory Committee, who participated in the development of this code.",
    "crumbs": [
      "Contributing",
      "NEON Code of Conduct"
    ]
  },
  {
    "objectID": "background/aop_background.html",
    "href": "background/aop_background.html",
    "title": "NEON Airborne Observation Platform",
    "section": "",
    "text": "NEON Airborne Remote Sensing\n\n\n\n\nThe AOP consists of three complete and comparable instrument payloads. Typically, two of the payloads are dedicated to collections of the NEON field sites while the third is dedicated to NEON’s Research Support services which support externally driven research. The primary sensors on each payload include\n\nA discrete and full-waveform lidar to provide three-dimensional structural information of the landscape,\nAn imaging spectrometer to allow discrimination of land cover types and chemical content of vegetation,\nA high-resolution digital camera to provide spatially accurate and detailed contextual information, and\nA GPS antenna and receiver and Inertial Measurement Unit (IMU) to provide high-accuracy positioning and orientation of the aircraft.\n\n\n\n\nThe AOP produces approximately 30 data products. The products are separated into categories of Level 1, Level 2, and Level 3 (L1, L2, L3). L1 represents the least processed data products. Additional processing steps are required to transition the L1 data to the derived L2 and L3 data. Broadly, the L1 and L2 products are provided by individual aircraft flight line, while L3 products are provided in 1 km by 1 km tiles. Generally, the data volume for L1 products is the highest and decreases for L2 and L3 products. Details of the different products within each Level can be found in the individual webpages for each sensor. All AOP data products can be found on the NEON Data Portal, and a subset of the L3 data products are available on Google Earth Engine.\n\n\nLevel 1 (L1) products include at-sensor radiance and surface reflectance which are distributed by flightline. The image data is georeferenced to the ITRF00 datum and projected into the appropriate UTM zone, and provided at 1 m spatial resolution. Both the radiance and reflectance image data are stored in an HDF5 file format that includes extensive metadata and data quality information. The HDF5 format was selected because of the flexibility it allows in storing associated metadata.\nLevel 2 (L2) products are derived from the L1 surface reflectance and are produced at the same spatial resolution (1 m), datum and map projection as the Level 1 products. The L2 products include a suite of spectral indices designed to strategically combine bands to highlight vegetation characteristics such as photosynthetic activity or water content. For example, NDVI (Normalized Difference Vegetation Index) is a well-known and commonly used vegetation index which combines information from the NIR and Red regions to estimate vegetative greenness and can be used as a proxy for plant health. The L2 products also include fPAR (fraction of photosynthetically active radiation) and LAI (leaf area index), products further derived from vegetation indices. Additionally, a surface Albedo product that estimates the integrated reflectance of all the NIS bands into a single value is also provided. All L2 products are distributed by flightline in a GeoTIFF (gtiff) format. Currently, all vegetation indices, water indices, fPAR, and LAI are delivered with associated simulated error images.\nLevel 3 (L3) products include mosaics of all L1 and L2 products, excluding at-sensor radiance, and are distributed as 1 km x 1 km tiles instead of flightlines. Tiles are created by making a full mosaic of all the data and sub-setting the 1 km x 1 km tiles. The tiles are designed so their boundaries are set to even 1000 m UTM coordinate intervals. During the mosaic generation, the algorithm preferentially selects pixels that were collected under the best weather conditions in regions with multiple potential pixels due to flightline overlap. If weather conditions were equivalent, pixels acquired nearest to nadir of the image acquisition are selected. Generally, this will correspond to pixels that are nearest to the center of the flightline. The tiles are created at the same spatial resolution (1 m) as the L1 and L2 products are in delivered in gtiff format, with the exception of the surface reflectance, which is delivered in HDF5 format.\n\n\nStarting in 2024, NEON began producing BRDF (Bidirectional Reflectance Distribution Function) and topographic corrected reflectance data, which include “bidirectional” in the name, and end with revision .002 in the Data Product IDs. As of 2025, these bidirectional reflectance are currently only available for data collected between 2022-2024. NEON is beginning to back-process earlier years (pre-2022) to apply the BRDF and topographic corrections. Please look at the data availability charts for each product on the data portal to determine whether the bidirectional data are available. Eventually, only bidirectional data products will be delivered, with the exception of the Level 1 Spectrometer orthorectified surface directional reflectance (DP1.30006.001), which will continue to be delivered, so that researchers who wish to carry out their own BRDF, topographic, or other corrections may do so.\nTable 1 below shows a full list of NEON’s spectrometer-derived data products, including the corresponding bidirectional reflectance data products, if applicable.\n\n\n\nTable 1: NEON AOP Imaging Spectrometer Datasets\n\n\n\n\n\nProduct Name\nLevel\nData Product ID (DPID)\nBRDF-Corrected DPID\n\n\n\n\nSpectrometer orthorectified at-sensor radiance\nL1\nDP1.30008.001\n\n\n\nSpectrometer orthorectified surface (bi)directional reflectance\nL1\nDP1.30006.001\nDP1.30006.002\n\n\nAlbedo - spectrometer - flightline\nL2\nDP2.30011.001\nDP2.30011.002\n\n\nLAI - spectrometer - flightline\nL2\nDP2.30012.001\nDP2.30012.002\n\n\nfPAR - spectrometer - flightline\nL2\nDP2.30014.001\nDP2.30014.002\n\n\nCanopy water indices - flightline\nL2\nDP2.30019.001\nDP2.30019.002\n\n\nVegetation indices - spectrometer - flightline\nL2\nDP2.30026.001\nDP2.30026.002\n\n\nAlbedo - spectrometer - mosaic\nL3\nDP3.30011.001\nDP3.30011.002\n\n\nLAI - Spectrometer - mosaic\nL3\nDP3.30012.001\nDP3.30012.002\n\n\nfPAR - spectrometer - mosaic\nL3\nDP3.30014.001\nDP3.30014.002\n\n\nCanopy water indices - mosaic\nL3\nDP3.30019.001\nDP3.30019.002\n\n\nVegetation indices - spectrometer - mosaic\nL3\nDP3.30026.001\nDP3.30026.002\n\n\n\n\n\n\nIn addition to the spectrometer-derived data products, NEON generates 5 lidar-derived products (Table 2) and 2 RGB camera data products (Table 3), summarized below. These data products provide valuable structural and visual information that compliment the spectrometer data.\n\n\n\n\n\n\n\nTable 2: NEON AOP Lidar Datasets\n\n\n\n\n\nProduct Name\nLevel\nData Product ID (DPID)\nATBD Document #\n\n\n\n\nLiDAR Slant Range Waveform\nL1\nDP1.30001.001\nNEON.DOC.001293\n\n\nDiscrete Return LiDAR Point Cloud\nL1\nDP1.30003.001\nNEON.DOC.001292, NEON.DOC.001288\n\n\nEcosystem Structure\nL3\nDP3.30015.001\nNEON.DOC.002387\n\n\nElevation – LiDAR\nL3\nDP3.30024.001\nNEON.DOC.002390\n\n\nSlope and Aspect – LiDAR\nL3\nDP3.30025.001\nNEON.DOC.003791\n\n\n\n\n\n\n\n\n\n\n\n\nTable 3: NEON AOP Camera Datasets\n\n\n\n\n\nProduct Name\nLevel\nData Product ID (DPID)\nATBD Document #\n\n\n\n\nHigh-resolution orthorectified camera imagery\nL1\nDP1.30010.001\nNEON.DOC.001211vB\n\n\nHigh-resolution orthorectified camera imagery mosaic\nL3\nDP3.30010.001\nNEON.DOC.005052vB",
    "crumbs": [
      "Background",
      "Airborne Observation Platform (AOP)"
    ]
  },
  {
    "objectID": "background/aop_background.html#neon-airborne-observation-platform-aop",
    "href": "background/aop_background.html#neon-airborne-observation-platform-aop",
    "title": "NEON Airborne Observation Platform",
    "section": "",
    "text": "NEON Airborne Remote Sensing\n\n\n\n\nThe AOP consists of three complete and comparable instrument payloads. Typically, two of the payloads are dedicated to collections of the NEON field sites while the third is dedicated to NEON’s Research Support services which support externally driven research. The primary sensors on each payload include\n\nA discrete and full-waveform lidar to provide three-dimensional structural information of the landscape,\nAn imaging spectrometer to allow discrimination of land cover types and chemical content of vegetation,\nA high-resolution digital camera to provide spatially accurate and detailed contextual information, and\nA GPS antenna and receiver and Inertial Measurement Unit (IMU) to provide high-accuracy positioning and orientation of the aircraft.\n\n\n\n\nThe AOP produces approximately 30 data products. The products are separated into categories of Level 1, Level 2, and Level 3 (L1, L2, L3). L1 represents the least processed data products. Additional processing steps are required to transition the L1 data to the derived L2 and L3 data. Broadly, the L1 and L2 products are provided by individual aircraft flight line, while L3 products are provided in 1 km by 1 km tiles. Generally, the data volume for L1 products is the highest and decreases for L2 and L3 products. Details of the different products within each Level can be found in the individual webpages for each sensor. All AOP data products can be found on the NEON Data Portal, and a subset of the L3 data products are available on Google Earth Engine.\n\n\nLevel 1 (L1) products include at-sensor radiance and surface reflectance which are distributed by flightline. The image data is georeferenced to the ITRF00 datum and projected into the appropriate UTM zone, and provided at 1 m spatial resolution. Both the radiance and reflectance image data are stored in an HDF5 file format that includes extensive metadata and data quality information. The HDF5 format was selected because of the flexibility it allows in storing associated metadata.\nLevel 2 (L2) products are derived from the L1 surface reflectance and are produced at the same spatial resolution (1 m), datum and map projection as the Level 1 products. The L2 products include a suite of spectral indices designed to strategically combine bands to highlight vegetation characteristics such as photosynthetic activity or water content. For example, NDVI (Normalized Difference Vegetation Index) is a well-known and commonly used vegetation index which combines information from the NIR and Red regions to estimate vegetative greenness and can be used as a proxy for plant health. The L2 products also include fPAR (fraction of photosynthetically active radiation) and LAI (leaf area index), products further derived from vegetation indices. Additionally, a surface Albedo product that estimates the integrated reflectance of all the NIS bands into a single value is also provided. All L2 products are distributed by flightline in a GeoTIFF (gtiff) format. Currently, all vegetation indices, water indices, fPAR, and LAI are delivered with associated simulated error images.\nLevel 3 (L3) products include mosaics of all L1 and L2 products, excluding at-sensor radiance, and are distributed as 1 km x 1 km tiles instead of flightlines. Tiles are created by making a full mosaic of all the data and sub-setting the 1 km x 1 km tiles. The tiles are designed so their boundaries are set to even 1000 m UTM coordinate intervals. During the mosaic generation, the algorithm preferentially selects pixels that were collected under the best weather conditions in regions with multiple potential pixels due to flightline overlap. If weather conditions were equivalent, pixels acquired nearest to nadir of the image acquisition are selected. Generally, this will correspond to pixels that are nearest to the center of the flightline. The tiles are created at the same spatial resolution (1 m) as the L1 and L2 products are in delivered in gtiff format, with the exception of the surface reflectance, which is delivered in HDF5 format.\n\n\nStarting in 2024, NEON began producing BRDF (Bidirectional Reflectance Distribution Function) and topographic corrected reflectance data, which include “bidirectional” in the name, and end with revision .002 in the Data Product IDs. As of 2025, these bidirectional reflectance are currently only available for data collected between 2022-2024. NEON is beginning to back-process earlier years (pre-2022) to apply the BRDF and topographic corrections. Please look at the data availability charts for each product on the data portal to determine whether the bidirectional data are available. Eventually, only bidirectional data products will be delivered, with the exception of the Level 1 Spectrometer orthorectified surface directional reflectance (DP1.30006.001), which will continue to be delivered, so that researchers who wish to carry out their own BRDF, topographic, or other corrections may do so.\nTable 1 below shows a full list of NEON’s spectrometer-derived data products, including the corresponding bidirectional reflectance data products, if applicable.\n\n\n\nTable 1: NEON AOP Imaging Spectrometer Datasets\n\n\n\n\n\nProduct Name\nLevel\nData Product ID (DPID)\nBRDF-Corrected DPID\n\n\n\n\nSpectrometer orthorectified at-sensor radiance\nL1\nDP1.30008.001\n\n\n\nSpectrometer orthorectified surface (bi)directional reflectance\nL1\nDP1.30006.001\nDP1.30006.002\n\n\nAlbedo - spectrometer - flightline\nL2\nDP2.30011.001\nDP2.30011.002\n\n\nLAI - spectrometer - flightline\nL2\nDP2.30012.001\nDP2.30012.002\n\n\nfPAR - spectrometer - flightline\nL2\nDP2.30014.001\nDP2.30014.002\n\n\nCanopy water indices - flightline\nL2\nDP2.30019.001\nDP2.30019.002\n\n\nVegetation indices - spectrometer - flightline\nL2\nDP2.30026.001\nDP2.30026.002\n\n\nAlbedo - spectrometer - mosaic\nL3\nDP3.30011.001\nDP3.30011.002\n\n\nLAI - Spectrometer - mosaic\nL3\nDP3.30012.001\nDP3.30012.002\n\n\nfPAR - spectrometer - mosaic\nL3\nDP3.30014.001\nDP3.30014.002\n\n\nCanopy water indices - mosaic\nL3\nDP3.30019.001\nDP3.30019.002\n\n\nVegetation indices - spectrometer - mosaic\nL3\nDP3.30026.001\nDP3.30026.002\n\n\n\n\n\n\nIn addition to the spectrometer-derived data products, NEON generates 5 lidar-derived products (Table 2) and 2 RGB camera data products (Table 3), summarized below. These data products provide valuable structural and visual information that compliment the spectrometer data.\n\n\n\n\n\n\n\nTable 2: NEON AOP Lidar Datasets\n\n\n\n\n\nProduct Name\nLevel\nData Product ID (DPID)\nATBD Document #\n\n\n\n\nLiDAR Slant Range Waveform\nL1\nDP1.30001.001\nNEON.DOC.001293\n\n\nDiscrete Return LiDAR Point Cloud\nL1\nDP1.30003.001\nNEON.DOC.001292, NEON.DOC.001288\n\n\nEcosystem Structure\nL3\nDP3.30015.001\nNEON.DOC.002387\n\n\nElevation – LiDAR\nL3\nDP3.30024.001\nNEON.DOC.002390\n\n\nSlope and Aspect – LiDAR\nL3\nDP3.30025.001\nNEON.DOC.003791\n\n\n\n\n\n\n\n\n\n\n\n\nTable 3: NEON AOP Camera Datasets\n\n\n\n\n\nProduct Name\nLevel\nData Product ID (DPID)\nATBD Document #\n\n\n\n\nHigh-resolution orthorectified camera imagery\nL1\nDP1.30010.001\nNEON.DOC.001211vB\n\n\nHigh-resolution orthorectified camera imagery mosaic\nL3\nDP3.30010.001\nNEON.DOC.005052vB",
    "crumbs": [
      "Background",
      "Airborne Observation Platform (AOP)"
    ]
  },
  {
    "objectID": "background/neon_background.html",
    "href": "background/neon_background.html",
    "title": "What is NEON?",
    "section": "",
    "text": "NEON is a continental-scale observation facility designed to collect long-term open-access ecological data to better understand the complexities of Earth’s ecosystems and how they are changing. NEON uses cutting-edge sensor networks, instrumentation, observational sampling, natural history archive facilities and remote sensing methods and technologies to collect data on plants, animals, soil, nutrients, freshwater and the atmosphere.\nNEON operates 81 field sites strategically located across 20 ecoclimatic Domains across the United States, including 47 terrestrial sites and 34 freshwater aquatic sites. When logistically possible, aquatic and terrestrial field sites are colocated (i.e. in close proximity) to support understanding of linkages across terrestrial and aquatic ecosystems and their interactions with the atmosphere. For example, Domain 08, the Ozarks Complex, has three co-located sets of terrestrial and aquatic field sites. These sites are situated along the same watershed system, creating a unique opportunity to study hydrology, nutrient transport, and biogeochemical cycling through the watershed.\nNEON delivers data products from three main sub-systems called the Airborne Observation Platform (AOP), Terrestrial and Aquatic Observational Systems (TOS/AOS), and the Instrumented Systems (TIS/AIS). The section below provides a brief summary of these sub-systems.",
    "crumbs": [
      "Background",
      "NEON Overview"
    ]
  },
  {
    "objectID": "background/neon_background.html#neon-airborne-observation-platform-aop",
    "href": "background/neon_background.html#neon-airborne-observation-platform-aop",
    "title": "What is NEON?",
    "section": "NEON Airborne Observation Platform (AOP)",
    "text": "NEON Airborne Observation Platform (AOP)\n\n\n\nNEON Airborne Remote Sensing\n\n\nAirborne remote sensing surveys are conducted over NEON field sites during peak greenness and provide quantitative information on land cover and changes to ecological structure and chemistry, including the presence and effects of invasive species. The surveys are supported by the NEON Airborne Observation Platform (AOP), a suite of earth observation instruments installed into a Twin Otter aircraft designed to collect high-resolution remote sensing data at low altitude. AOP was designed to collect regional-scale landscape information at the NEON field sites. The AOP maps areas where NEON’s observational and instrumented sampling is occurring and allows relationships to be drawn between NEON’s detailed in-situ observations to the broader environmental and ecological conditions.\nPlease see the next section  for more details on the AOP including a summary of the data products provided.",
    "crumbs": [
      "Background",
      "NEON Overview"
    ]
  },
  {
    "objectID": "background/neon_background.html#neon-field-data",
    "href": "background/neon_background.html#neon-field-data",
    "title": "What is NEON?",
    "section": "NEON Field Data",
    "text": "NEON Field Data\nIn addition to the AOP remote sensing data, NEON also provides Observational Sampling (OS) data and Instrumented Sampling (IS) data at terrestrial and aquatic sites. The field and instrumented sampling are briefly described below, but we encourage exploring the NEON website further for a more detailed understanding of the sensors and data products provided by the OS and IS groups.\n\nObservational Sampling\n\n\n\nNEON Observational Samples\n\n\nNEON field scientists collect a broad variety of observations and samples at terrestrial and aquatic field sites at regular intervals throughout the year. The data and samples collected by NEON’s Aquatic Observation System (AOS) and Terrestrial Observation System (TOS) are designed to provide standardized, continentally distributed observations of organisms, biogeochemistry, and physical properties.\n\n\nInstrumented Sampling\n\n\n\nNEON Instrumented Sampling\n\n\nNEON deploys automated instruments to collect meteorological, soil, phenological, surface water, and groundwater data at NEON field sites.\nWhere logistically possible, NEON colocated aquatic sites with terrestrial sites (21 in total) to support an understanding of linkages across atmospheric, terrestrial, and aquatic ecosystems. The suite of OS, IS, and AOP data provide an unparalleled opportunity to study ecosystem-level change over time in the United States.",
    "crumbs": [
      "Background",
      "NEON Overview"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Working with NEON Airborne Remote Sensing Data in Google Earth Engine",
    "section": "",
    "text": "The U.S. NSF’s National Ecological Observatory Network (NEON) offers extensive ecological data across various temporal and spatial scales. NEON’s Airborne Observation Platform (AOP) captures high-resolution hyperspectral imagery, lidar, and RGB photography at 81 U.S. sites, with data spanning 2-10 years. In 2024, 5 AOP datasets were added to the Google Earth Engine publisher catalog, providing another means of accessing and working with NEON data.\nThis workshop introduces participants to NEON AOP and field datasets through reproducible live-coding exercises in Google Earth Engine. Attendees will learn about ecological applications using remote sensing data, and will gain a better understanding of quality assurance considerations. The session concludes with demonstrations of workflows that integrate ground-based data for machine learning analyses to generate regional-scale models.",
    "crumbs": [
      "Welcome",
      "2025 ESA Workshop"
    ]
  },
  {
    "objectID": "index.html#agenda",
    "href": "index.html#agenda",
    "title": "Working with NEON Airborne Remote Sensing Data in Google Earth Engine",
    "section": "Agenda",
    "text": "Agenda\n\n\n\n\n\n\n\n\nTime\nDescription\nLeads/Instructors\n\n\n\n\n11:45 PM\nIntroduction\nBridget Hass, Kate Murphy and Sam Roy\n\n\n11:50 AM\nOverview of NEON Airborne Observation Platform\nBridget Hass and Kate Murphy\n\n\n12:05 AM\nSetting up Google Earth Engine\nSam Roy\n\n\n12:15 PM\nLesson 1: Download and Explore NEON AOP Hyperspectral Data\nBridget Hass\n\n\n12:35 PM\nLesson 2: Reflectance QA Considerations\nBridget Hass\n\n\n12:55 PM\nLesson 3: Hyperspectral Classification\nSam Roy\n\n\n1:05 PM\nDiscussion and Wrap Up\nAll",
    "crumbs": [
      "Welcome",
      "2025 ESA Workshop"
    ]
  },
  {
    "objectID": "index.html#contact-info",
    "href": "index.html#contact-info",
    "title": "Working with NEON Airborne Remote Sensing Data in Google Earth Engine",
    "section": "Contact Info",
    "text": "Contact Info\nNEON AOP\nOrganization: National Ecological Observatory Network Airborne Observation Platform (NEON AOP)1\nWebsite: https://neonscience.org/\nContact: https://www.neonscience.org/about/contact-us/\n1NEON is a project fully funded by the National Science Foundation and operated by Battelle.\nORNL DAAC\nOrganization: NASA Earthdata Data Center, Oak Ridge National Laboratory Distributed Active Archive Center (ORNL DAAC)\nWebsite: https://www.earthdata.nasa.gov/centers/ornl-daac\nContact:\nNASA Earthdata Forum: https://forum.earthdata.nasa.gov/\nORNL DAAC - uso@daac.ornl.gov",
    "crumbs": [
      "Welcome",
      "2025 ESA Workshop"
    ]
  },
  {
    "objectID": "setup/prerequisites.html",
    "href": "setup/prerequisites.html",
    "title": "Prerequisites",
    "section": "",
    "text": "Prerequisites\nParticipants should have basic familiarity with Google Earth Engine and experience coding in a scientific language (e.g., Python, R, JavaScript) is recommended. Participants must sign up for a Google Earth Engine account and set up a cloud project to follow along with the live-coding exercises.",
    "crumbs": [
      "Setup Instructions",
      "Prerequisites"
    ]
  },
  {
    "objectID": "tutorials/01_intro_to_neon_aop_gee_datasets.html",
    "href": "tutorials/01_intro_to_neon_aop_gee_datasets.html",
    "title": "Introduction to AOP Public Datasets in Google Earth Engine (GEE)",
    "section": "",
    "text": "Google Earth Engine (GEE) is a free and powerful cloud-computing platform for carrying out remote sensing and geospatial data analysis. In this tutorial, we introduce you to the NEON AOP datasets that have been added to Google Earth Engine as Publisher Datasets.\n\n  \n\nNEON is planning to add the full archive of AOP L3 Surface Bidirectional Reflectance, LiDAR Elevation, Ecosystem Structure, and High-resolution orthorectified camera imagery. Since the L3 Surface Directional Reflectance is being replaced by the bidirectional (Bidirectional Reflectance Distribution Function (BRDF) and topographic corrected) reflectance as that becomes available, we are only adding directional reflectance data to GEE upon request. As of July 2025, bidirectional data is only available for AOP data collected between 2022-2024, but re-processing of older AOP data (2013-2021) will begin in mid-2025. Please see the tutorial Introduction to Bidirectional Hyperspectral Reflectance Data in Python for more information on the differences between the directional and bidirectional reflectance data products.\nIt will take time for the full archive of AOP data to be added to GEE, but NEON has been ramping up data additions starting in Fall 2024. This tutorial shows you how to find which data are currently available. If there are certain NEON sites and years of data you would like to see added to Google Earth Engine sooner, use the NEON Contact Us form to request this, and include “Google Earth Engine Remote Sensing Data” in the text.\n\n\n\nAfter completing this activity, you will become familiar with: * Google Earth Engine (GEE) * NEON AOP Image Collections in GEE\nAnd you will be able to: * Write and run basic JavaScript code in the GEE Code Editor * Discover which NEON AOP datasets are available in GEE * Explore the NEON AOP GEE Image Collections * Plot an RGB image of a reflectance dataset * Compare bidirectional and directional reflectance datasets\n\n\n\n\nA Google or gmail (@gmail.com) account.\nAn Earth Engine account. You can sign up for an Earth Engine account here: https://earthengine.google.com/new_signup/. Click on “Register a Noncommercial or Commercial Cloud Project”, and on the next promp select “Unpaid Usage” and select the Project Type to create a free non-commercial account. For more information, refer to Noncommercial Earth Engine.\nA Google Cloud Project. See  Set up your Earth Engine enabled Cloud Project.\nA basic understanding of the GEE Code Editor and the GEE JavaScript API.\n\n\n\n\nIf this is your first time using GEE, we recommend starting on the Google Developers website, and working through some of the introductory tutorials. The links below are good places to start. * Get Started with Earth-Engine * GEE JavaScript Tutorial\n\n\n\n\nAOP has currently added a subset of AOP Level 3 (tiled) data products at over 50 NEON sites spanning 10 years on GEE (as of Jan 2025). The NEON data products that have been made available on GEE can be currently be found on the  GEE Datasets page, if you search for “NEON” as follows:\n\n  \n\nIn the code editor, NEON datasets can be accessed through the projects/neon-prod-earthengine folder with an appended suffix of the Acronym and Revision Number, shown in the table below. For example, the Surface Directional Reflectance can be found under the path projects/neon-prod-earthengine/assets/HSI_REFL/001. The table below summarizes the Acronyms and Revisions for each data product, and can be used as a reference for reading in AOP GEE datasets. You will learn how to access and read in these data products in the next part of this lesson.\n\n\n\n\n\n\n\n\n\nAcronym\nRevision\nData Product\nData Product ID\n\n\n\n\nHSI_REFL\n001\nSurface Directional Reflectance\nDP3.30006.001\n\n\nHSI_REFL\n002\nSurface Bidirectional Reflectance\nDP3.30006.002\n\n\nRGB\n001\nRed Green Blue (Camera Imagery)\nDP3.30010.001\n\n\nDEM\n001\nDigital Surface and Terrain Models (DSM/DTM)\nDP3.30024.001\n\n\nCHM\n001\nEcosystem Structure (Canopy Height Model; CHM)\nDP3.30015.001\n\n\n\n\n\n\nOnce you have set up your Google Earth Engine account you can navigate to the Earth Engine Code Editor. The diagram below, from the Earth-Engine Playground, shows the main components of the code editor. If you have used other programming languages such as R, Python, or Matlab, this should look fairly similar to other Integrated Development Environments (IDEs) you may have worked with. The main difference is that this has an interactive map at the bottom, similar to Google Maps and Google Earth. We encourage you to play around with the interactive map, or explore the ee documentation, linked above, to gain familiarity with the various features.\n\n  \n\n\n\n\nAOP data can currently be accessed through GEE through the projects/neon-prod-earthengine/assets/ folder. In the remainder of this lesson, we will look at the five available AOP datasets, or ImageCollections.\nAn ImageCollection is simply a group of images. To find publicly available datasets (primarily satellite data), you can explore the Earth Engine Data Catalog. The following steps will walk you through how to read in AOP Image Collections in the Code Editor.\nIn your code editor, copy and run the following lines of code to create 5 ImageCollection variables containing the Surface Directional Reflectance (HSI_REFL/001), Surface Bidirectional Reflectance (HSI_REFL/002), Camera Imagery (RGB), Canopy Height Model (CHM), and Digital Elevation Model (DEM) raster data sets.\n//read in the AOP image collections as variables\n\nvar refl001 = ee.ImageCollection('projects/neon-prod-earthengine/assets/HSI_REFL/001')\n\nvar refl002 = ee.ImageCollection('projects/neon-prod-earthengine/assets/HSI_REFL/002')\n\nvar rgb = ee.ImageCollection('projects/neon-prod-earthengine/assets/RGB/001') \n\nvar chm = ee.ImageCollection('projects/neon-prod-earthengine/assets/CHM/001')\n\nvar dem = ee.ImageCollection('projects/neon-prod-earthengine/assets/DEM/001')\nA few tips for the working in the Code Editor: - In the left panel of the code editor, there is a Docs tab which includes API documentation on built in functions, showing the expected input arguments. We encourage you to refer to this documentation, as well as the  GEE JavaScript Tutorial to familiarize yourself with GEE and the JavaScript programming language. - If you have an error in your code, a red error message will show up in the Console (in the right panel), which tells you the line that failed. - Save your code frequently! If you try to leave your code while it is unsaved, you will be prompted that there are unsaved changes in the editor.\nWhen you Run the code above (by clicking on the Run above the code editor), you will notice that the lines of code become underlined in red, the same as you would see for a spelling error in most text editors. If you hover over each of the lines of codes, you will see a message pop up that prompts you to Convert the variable into an import record.\n\n  \n\nIf you click Convert, the line of code will disappear and the variable will be imported into your session directly, and will show up at the top of the code editor. Go ahead and convert the variables for all three lines of code, so you should see the following. Tip: if you type Ctrl-z, you can re-generate the line of code, and the variable will still show up in the imported variables at the top of the editor. It is recommended to retain the code that reads in each variable, for reproducibility. If you don’t do this, and wish to share this code with someone else, or run the code outside of your current code editor, the imported variables will not be saved and any subsequent code referring to this variable will result in an error message.\n\n  \n\nNote that each of these imported variables can now be expanded, using the arrow to the left of each. These variables now show associated information including type, id, and version.\nInformation about the image collections can also be found in a slightly more user-friendly format if you click on the blue link, eg. projects/neon-prod-earthengine/CHM/001. Below we’ll show the window that pops-up when you click on the CHM link. We encourage you to explore all of the AOP datasets similarly. Note: You can also search for the NEON AOP image collections through the search bar on the Earth Engine Data Catalog webpage. The dataset page also contains all the information about the data product, eg. NEON Canopy Height Model (CHM).\n\n  \n\nThe end of the description includes a link to the Data Product landing page on the NEON Data Portal, as well as the Quick Start Guide, which includes links to all the documentation pertaining to this NEON data product, including the Algorithm Theoretical Basis Documents (ATBDs). Click on the other tabs to explore more about this data product. These tabs include DESCRIPTION, BANDS, IMAGE PROPERTIES, TERMS OF USE, AND CITATIONS.\nTIP: You can also search for NEON data products through Code Editor by typing “NEON” in the search bar as shown below:\n\n  \n\n\n\n\nSince we are adding AOP data to GEE on a rolling basis, the first thing you may want to do after reading in the image collections is to determine which datasets are currently available on GEE. A quick way to do this is shown below:\n// list all available images in the NEON Surface Directional Reflectance Image Collection:\nprint('NEON Images in the Directional Reflectance Collection',\n      refl001.aggregate_array('system:index'))\n      \n// list all available images in the NEON Surface Bidirectional Reflectance Image Collection:\nprint('NEON Images in the Bidirectional Reflectance Collection',\n      refl002.aggregate_array('system:index'))\n\n// list all available images in the NEON DEM image collection:\nprint('NEON Images in the DEM Collection',\n      dem.aggregate_array('system:index'))\n\n// list all available images in the NEON CHM image collection:\nprint('NEON Images in the CHM Collection',\n      chm.aggregate_array('system:index'))\n\n// list all available images in the NEON CHM image collection:\nprint('NEON Images in the RGB Camera Collection',\n      rgb.aggregate_array('system:index'))\nIn the Console tab to the right of the code, you will see a list of all available images. Expand each List to see the data available for each Image Collection. The names of the all the images follow the format YEAR_SITE_#, so you can identify the site and year of data this way. The number at the end is the Visit #; AOP typically visits each site 3 out of every 5 years, so the visit number indicates the cumulative number of times AOP has visited that site. Occasionally, AOP may re-visit a site twice in the same year.\n\n  \n\n\n\n\nNext, we can explore some filtering options to pull out individual images from an Image Collection. In the example shown below, we can filter by the date (.filterDate) by providing a date range, and filter by other properties, such as the NEON site code, using .filterMetadata. For this example we’ll pull in an image from the NEON site Lyndon B. Johnson National Grassland NEON (CLBJ).\n// read in a single reflectance image at the NEON site CLBJ in 2021\nvar refl001_CLBJ_2021 = refl001\n  .filterDate('2021-01-01', '2021-12-31') // filter by date - 2021\n  .filterMetadata('NEON_SITE', 'equals', 'CLBJ') // filter by site\n  .first(); // select the first one to pull out a single image\n\n\n\nNext let’s take a look at the Image Properties.\n// look at the image properties\nvar clbj2021_refl_properties = refl001_CLBJ_2021.toDictionary()\nprint('CLBJ 2021 Directional Reflectance Properties:', clbj2021_refl_properties)\nLook in the Console for the properties, you can expand by clicking on the arrow to the left of the Object (438 properties). Here you can see some metadata about this image. Scroll down and you’ll get to a number of properties starting with WL_FWHM_B###. These are the WaveLength (WL) and Full Width Half Max (FWHM) values, in nanometers, corresponding to each band (Bands 001 - 426). You may wish to refer to this wavelength information to determine which bands you wish to display, eg. if you want to show a false color image instead of a true color (RGB) image. For a full description of what each of the Image Properties mean, you can look at the IMAGE PROPERTIES tab as explained in the previous section, or find it in the Earth Engine Data Catalog.\n\n  \n\n\n\n\nWhen working with NEON data, whether downloaded from the Data Portal or on GEE, we always recommend checking whether the data are Provisional or Released, and the release tag of the data. On GEE, this information is included in the image properties PROVISIONAL_RELEASED and RELEASE_YEAR. If the data is released, the property RELEASE_YEAR will display the year of the release. The code chunk below shows how to display the release information for the CLBJ 2021 directional reflectance data.\n// determine the release information for this image\nvar clbj2021_release_status = clbj2021_refl_properties.select(['PROVISIONAL_RELEASED']);\nprint('CLBJ 2021 Directional Reflectance Release Status:', clbj2021_release_status)\n\nvar clbj2021_release_year = clbj2021_refl_properties.select(['RELEASE_YEAR']);\nprint('CLBJ 2021 Directional Reflectance Release Year:', clbj2021_release_year)\nIn this example, the data is part of RELEASE-2024.\nFor more information on NEON releases, refer to the NEON Data Product Revisions and Releases page. There is a short period each year in January where AOP data on the NEON Data Portal may be in flux in preparation for an upcoming data release (typically end of January). GEE datasets are planned to be kept up to date with the current release, however there may be a lag period between the annual release and data updates on GEE. Data on GEE should be updated to match the current release by the end of February each year. For current information around the release status and data quality issue notices, you can follow NEON Data Notifications.\n\n\n\nFinally, let’s plot a true color image (red-green-blue or RGB composite) of the reflectance data that we’ve read into the variable refl001_CBLJ_2021. To do this, first we pull out the RGB bands, set visualization parameters, center the map over the site, and then add the map using Map.addLayer. There are a couple ways you can center the Map to the location you want. One is to use Map.centerObject and you can provide the image you want to center; otherwise you can specify the latitude and longitude, shown commented-out in the code chunk below.\n// pull out the red, green, and blue bands\nvar refl001_CLBJ_2021_RGB = refl001_CLBJ_2021.select(['B053', 'B035', 'B019']);\n\n// set visualization parameters\nvar refl_rgb_vis = {min: 0, max: 1260, gamma: 0.8};\n\n// use centerObject to center on the reflectance data, 13 is the zoom level\nMap.centerObject(refl001_CLBJ_2021, 13)\n\n// alternatively you could specify the lat / lon of the site, set zoom to 13\n// you can find the field site lat/lon here https://www.neonscience.org/field-sites/clbj\n// Map.setCenter(-97.57, 33.40, 13);\n\n// add this RGB layer to the Map and give it a title\nMap.addLayer(refl001_CLBJ_2021_RGB, refl_rgb_vis, 'CLBJ 2021 Directional Reflectance RGB');\nWhen you run the code you should now see the true color image on the map! You can zoom in and out and explore some of the other interactive options on your own.\n\n  \n\n\n\n\nLastly, let’s also look at a bidirectional data product at the same site, and you can explore the differences between the directional and bidirectional reflectance. We will also display the release information for this data.\n// read in a bidirectional reflectance image at the NEON site CLBJ in 2022\nvar refl002_CLBJ_2022 = refl002\n  .filterDate('2022-01-01', '2022-12-31') // filter by date - 2022\n  .filterMetadata('NEON_SITE', 'equals', 'CLBJ') // filter by site\n  .first(); // select the first one to pull out a single image\n\n// read the properties into a variable\nvar clbj2022_refl_properties = refl002_CLBJ_2022.toDictionary()\n\n// determine the release information for this BRDF-corrected image\nvar clbj2022_release_status = clbj2022_refl_properties.select(['PROVISIONAL_RELEASED']);\nprint('CLBJ 2022 Bidirectional Reflectance Release Status:', clbj2022_release_status)\n\n// if you try to read in the release year, it will throw an error\n// since this data product is still PROVISIONAL, there is no release year\n// comment out these lines below to remove\nvar clbj2022_release_year = clbj2022_refl_properties.select(['RELEASE_YEAR']);\nprint('CLBJ 2022 Bidirectional Reflectance Release Year:', clbj2022_release_year)\n  \n// pull out the red, green, and blue bands\nvar refl002_CLBJ_2022_RGB = refl002_CLBJ_2022.select(['B053', 'B035', 'B019']);\n\n// add this RGB layer to the Map and give it a title\nMap.addLayer(refl002_CLBJ_2022_RGB, refl_rgb_vis, 'CLBJ 2022 Bidirectional Reflectance RGB');\n\n  \n\nIf your code has any errors they will display in the Console tab in red. In this example, we tried to print out a property that does not exist because the data is Provisional, so there is no RELEASE_YEAR. You can comment out the lines of code starting with var clbj2022_release_year to prevent the error from displaying. If your code is not running as expected, errors displayed in the Console can be helpful for troubleshooting, as it will tell you how and where your code failed. Print statements throughout the code can also be helpful.\nNote that bidirectional reflectance data will remain provisional in 2025, since it is a new data product (as of 2024), and is planned to be incorporated into RELEASE-2026.\nYou can toggle between the two layers by selecting the “Layers” tab in the upper right corner of the Map window. Check and uncheck the two layers (2021 and 2022) to see the differences. You can also use the slider to the right of the layer name to make one layer partially transparent. What observations can you make about these two datasets?\n\n  \n\nThe BRDF and topographic corrections typically visibly improve striping (or BRDF effects) between adjacent flightlines, as we can see with these datasets at CLBJ, where the 2022 bidirectional reflectance (left) looks much more seamless than the 2021 directional reflectance data (right), which has some visible vertical artifacts. For most NEON sites, the flight lines are oriented N-S so the stripes in the directional reflectance data will be vertical, but there are a few sites with slightly different flight plans.\n\n\n\nYou did it! You now have a basic understanding of the GEE Code Editor and its different components. You have also learned how to read a NEON AOP ImageCollection into a variable, import the variable into your session, and navigate through the ImageCollection Asset details to display information about the collection. You learned to read in an individual reflectance image, explore the image properties, and display a map of a true color image (RGB composite). And finally, you explored some of the differences between the directional and bidirectional (BRDF- and topographic corrected) reflectance data products at the site CLBJ.\nIt doesn’t seem like we’ve done much so far, but this is a already great achievement! With just a few lines of code, you can import an entire AOP hyperspectral dataset, which in most other coding environments, is more involved. One of the major challenges to working with AOP reflectance data is its large data volume, which typically requires high-performance computing environments to read in the data, visualize, and analyze it. There are also limited open-source tools for working with hyperspectral data; many of the established software suites require proprietary (and often expensive) licenses. In this lesson, with minimal code, we have loaded spectral, lidar, and camera data covering an entire AOP site, and are ready to start exploring and analyzing the data in a free geospatial cloud-computing platform.\n\n\n\nInto to AOP GEE Image Collections",
    "crumbs": [
      "Tutorials",
      "1 Introduction to NEON AOP GEE Datasets"
    ]
  },
  {
    "objectID": "tutorials/01_intro_to_neon_aop_gee_datasets.html#objectives",
    "href": "tutorials/01_intro_to_neon_aop_gee_datasets.html#objectives",
    "title": "Introduction to AOP Public Datasets in Google Earth Engine (GEE)",
    "section": "",
    "text": "After completing this activity, you will become familiar with: * Google Earth Engine (GEE) * NEON AOP Image Collections in GEE\nAnd you will be able to: * Write and run basic JavaScript code in the GEE Code Editor * Discover which NEON AOP datasets are available in GEE * Explore the NEON AOP GEE Image Collections * Plot an RGB image of a reflectance dataset * Compare bidirectional and directional reflectance datasets",
    "crumbs": [
      "Tutorials",
      "1 Introduction to NEON AOP GEE Datasets"
    ]
  },
  {
    "objectID": "tutorials/01_intro_to_neon_aop_gee_datasets.html#requirements",
    "href": "tutorials/01_intro_to_neon_aop_gee_datasets.html#requirements",
    "title": "Introduction to AOP Public Datasets in Google Earth Engine (GEE)",
    "section": "",
    "text": "A Google or gmail (@gmail.com) account.\nAn Earth Engine account. You can sign up for an Earth Engine account here: https://earthengine.google.com/new_signup/. Click on “Register a Noncommercial or Commercial Cloud Project”, and on the next promp select “Unpaid Usage” and select the Project Type to create a free non-commercial account. For more information, refer to Noncommercial Earth Engine.\nA Google Cloud Project. See  Set up your Earth Engine enabled Cloud Project.\nA basic understanding of the GEE Code Editor and the GEE JavaScript API.",
    "crumbs": [
      "Tutorials",
      "1 Introduction to NEON AOP GEE Datasets"
    ]
  },
  {
    "objectID": "tutorials/01_intro_to_neon_aop_gee_datasets.html#additional-resources",
    "href": "tutorials/01_intro_to_neon_aop_gee_datasets.html#additional-resources",
    "title": "Introduction to AOP Public Datasets in Google Earth Engine (GEE)",
    "section": "",
    "text": "If this is your first time using GEE, we recommend starting on the Google Developers website, and working through some of the introductory tutorials. The links below are good places to start. * Get Started with Earth-Engine * GEE JavaScript Tutorial",
    "crumbs": [
      "Tutorials",
      "1 Introduction to NEON AOP GEE Datasets"
    ]
  },
  {
    "objectID": "tutorials/01_intro_to_neon_aop_gee_datasets.html#aop-gee-data-access",
    "href": "tutorials/01_intro_to_neon_aop_gee_datasets.html#aop-gee-data-access",
    "title": "Introduction to AOP Public Datasets in Google Earth Engine (GEE)",
    "section": "",
    "text": "AOP has currently added a subset of AOP Level 3 (tiled) data products at over 50 NEON sites spanning 10 years on GEE (as of Jan 2025). The NEON data products that have been made available on GEE can be currently be found on the  GEE Datasets page, if you search for “NEON” as follows:\n\n  \n\nIn the code editor, NEON datasets can be accessed through the projects/neon-prod-earthengine folder with an appended suffix of the Acronym and Revision Number, shown in the table below. For example, the Surface Directional Reflectance can be found under the path projects/neon-prod-earthengine/assets/HSI_REFL/001. The table below summarizes the Acronyms and Revisions for each data product, and can be used as a reference for reading in AOP GEE datasets. You will learn how to access and read in these data products in the next part of this lesson.\n\n\n\n\n\n\n\n\n\nAcronym\nRevision\nData Product\nData Product ID\n\n\n\n\nHSI_REFL\n001\nSurface Directional Reflectance\nDP3.30006.001\n\n\nHSI_REFL\n002\nSurface Bidirectional Reflectance\nDP3.30006.002\n\n\nRGB\n001\nRed Green Blue (Camera Imagery)\nDP3.30010.001\n\n\nDEM\n001\nDigital Surface and Terrain Models (DSM/DTM)\nDP3.30024.001\n\n\nCHM\n001\nEcosystem Structure (Canopy Height Model; CHM)\nDP3.30015.001",
    "crumbs": [
      "Tutorials",
      "1 Introduction to NEON AOP GEE Datasets"
    ]
  },
  {
    "objectID": "tutorials/01_intro_to_neon_aop_gee_datasets.html#get-started-with-google-earth-engine",
    "href": "tutorials/01_intro_to_neon_aop_gee_datasets.html#get-started-with-google-earth-engine",
    "title": "Introduction to AOP Public Datasets in Google Earth Engine (GEE)",
    "section": "",
    "text": "Once you have set up your Google Earth Engine account you can navigate to the Earth Engine Code Editor. The diagram below, from the Earth-Engine Playground, shows the main components of the code editor. If you have used other programming languages such as R, Python, or Matlab, this should look fairly similar to other Integrated Development Environments (IDEs) you may have worked with. The main difference is that this has an interactive map at the bottom, similar to Google Maps and Google Earth. We encourage you to play around with the interactive map, or explore the ee documentation, linked above, to gain familiarity with the various features.",
    "crumbs": [
      "Tutorials",
      "1 Introduction to NEON AOP GEE Datasets"
    ]
  },
  {
    "objectID": "tutorials/01_intro_to_neon_aop_gee_datasets.html#read-aop-data-collections-into-gee-using-ee.imagecollection",
    "href": "tutorials/01_intro_to_neon_aop_gee_datasets.html#read-aop-data-collections-into-gee-using-ee.imagecollection",
    "title": "Introduction to AOP Public Datasets in Google Earth Engine (GEE)",
    "section": "",
    "text": "AOP data can currently be accessed through GEE through the projects/neon-prod-earthengine/assets/ folder. In the remainder of this lesson, we will look at the five available AOP datasets, or ImageCollections.\nAn ImageCollection is simply a group of images. To find publicly available datasets (primarily satellite data), you can explore the Earth Engine Data Catalog. The following steps will walk you through how to read in AOP Image Collections in the Code Editor.\nIn your code editor, copy and run the following lines of code to create 5 ImageCollection variables containing the Surface Directional Reflectance (HSI_REFL/001), Surface Bidirectional Reflectance (HSI_REFL/002), Camera Imagery (RGB), Canopy Height Model (CHM), and Digital Elevation Model (DEM) raster data sets.\n//read in the AOP image collections as variables\n\nvar refl001 = ee.ImageCollection('projects/neon-prod-earthengine/assets/HSI_REFL/001')\n\nvar refl002 = ee.ImageCollection('projects/neon-prod-earthengine/assets/HSI_REFL/002')\n\nvar rgb = ee.ImageCollection('projects/neon-prod-earthengine/assets/RGB/001') \n\nvar chm = ee.ImageCollection('projects/neon-prod-earthengine/assets/CHM/001')\n\nvar dem = ee.ImageCollection('projects/neon-prod-earthengine/assets/DEM/001')\nA few tips for the working in the Code Editor: - In the left panel of the code editor, there is a Docs tab which includes API documentation on built in functions, showing the expected input arguments. We encourage you to refer to this documentation, as well as the  GEE JavaScript Tutorial to familiarize yourself with GEE and the JavaScript programming language. - If you have an error in your code, a red error message will show up in the Console (in the right panel), which tells you the line that failed. - Save your code frequently! If you try to leave your code while it is unsaved, you will be prompted that there are unsaved changes in the editor.\nWhen you Run the code above (by clicking on the Run above the code editor), you will notice that the lines of code become underlined in red, the same as you would see for a spelling error in most text editors. If you hover over each of the lines of codes, you will see a message pop up that prompts you to Convert the variable into an import record.\n\n  \n\nIf you click Convert, the line of code will disappear and the variable will be imported into your session directly, and will show up at the top of the code editor. Go ahead and convert the variables for all three lines of code, so you should see the following. Tip: if you type Ctrl-z, you can re-generate the line of code, and the variable will still show up in the imported variables at the top of the editor. It is recommended to retain the code that reads in each variable, for reproducibility. If you don’t do this, and wish to share this code with someone else, or run the code outside of your current code editor, the imported variables will not be saved and any subsequent code referring to this variable will result in an error message.\n\n  \n\nNote that each of these imported variables can now be expanded, using the arrow to the left of each. These variables now show associated information including type, id, and version.\nInformation about the image collections can also be found in a slightly more user-friendly format if you click on the blue link, eg. projects/neon-prod-earthengine/CHM/001. Below we’ll show the window that pops-up when you click on the CHM link. We encourage you to explore all of the AOP datasets similarly. Note: You can also search for the NEON AOP image collections through the search bar on the Earth Engine Data Catalog webpage. The dataset page also contains all the information about the data product, eg. NEON Canopy Height Model (CHM).\n\n  \n\nThe end of the description includes a link to the Data Product landing page on the NEON Data Portal, as well as the Quick Start Guide, which includes links to all the documentation pertaining to this NEON data product, including the Algorithm Theoretical Basis Documents (ATBDs). Click on the other tabs to explore more about this data product. These tabs include DESCRIPTION, BANDS, IMAGE PROPERTIES, TERMS OF USE, AND CITATIONS.\nTIP: You can also search for NEON data products through Code Editor by typing “NEON” in the search bar as shown below:",
    "crumbs": [
      "Tutorials",
      "1 Introduction to NEON AOP GEE Datasets"
    ]
  },
  {
    "objectID": "tutorials/01_intro_to_neon_aop_gee_datasets.html#aop-gee-data-availability",
    "href": "tutorials/01_intro_to_neon_aop_gee_datasets.html#aop-gee-data-availability",
    "title": "Introduction to AOP Public Datasets in Google Earth Engine (GEE)",
    "section": "",
    "text": "Since we are adding AOP data to GEE on a rolling basis, the first thing you may want to do after reading in the image collections is to determine which datasets are currently available on GEE. A quick way to do this is shown below:\n// list all available images in the NEON Surface Directional Reflectance Image Collection:\nprint('NEON Images in the Directional Reflectance Collection',\n      refl001.aggregate_array('system:index'))\n      \n// list all available images in the NEON Surface Bidirectional Reflectance Image Collection:\nprint('NEON Images in the Bidirectional Reflectance Collection',\n      refl002.aggregate_array('system:index'))\n\n// list all available images in the NEON DEM image collection:\nprint('NEON Images in the DEM Collection',\n      dem.aggregate_array('system:index'))\n\n// list all available images in the NEON CHM image collection:\nprint('NEON Images in the CHM Collection',\n      chm.aggregate_array('system:index'))\n\n// list all available images in the NEON CHM image collection:\nprint('NEON Images in the RGB Camera Collection',\n      rgb.aggregate_array('system:index'))\nIn the Console tab to the right of the code, you will see a list of all available images. Expand each List to see the data available for each Image Collection. The names of the all the images follow the format YEAR_SITE_#, so you can identify the site and year of data this way. The number at the end is the Visit #; AOP typically visits each site 3 out of every 5 years, so the visit number indicates the cumulative number of times AOP has visited that site. Occasionally, AOP may re-visit a site twice in the same year.",
    "crumbs": [
      "Tutorials",
      "1 Introduction to NEON AOP GEE Datasets"
    ]
  },
  {
    "objectID": "tutorials/01_intro_to_neon_aop_gee_datasets.html#filter-by-image-properties-and-display-a-true-color-image",
    "href": "tutorials/01_intro_to_neon_aop_gee_datasets.html#filter-by-image-properties-and-display-a-true-color-image",
    "title": "Introduction to AOP Public Datasets in Google Earth Engine (GEE)",
    "section": "",
    "text": "Next, we can explore some filtering options to pull out individual images from an Image Collection. In the example shown below, we can filter by the date (.filterDate) by providing a date range, and filter by other properties, such as the NEON site code, using .filterMetadata. For this example we’ll pull in an image from the NEON site Lyndon B. Johnson National Grassland NEON (CLBJ).\n// read in a single reflectance image at the NEON site CLBJ in 2021\nvar refl001_CLBJ_2021 = refl001\n  .filterDate('2021-01-01', '2021-12-31') // filter by date - 2021\n  .filterMetadata('NEON_SITE', 'equals', 'CLBJ') // filter by site\n  .first(); // select the first one to pull out a single image",
    "crumbs": [
      "Tutorials",
      "1 Introduction to NEON AOP GEE Datasets"
    ]
  },
  {
    "objectID": "tutorials/01_intro_to_neon_aop_gee_datasets.html#explore-image-properties",
    "href": "tutorials/01_intro_to_neon_aop_gee_datasets.html#explore-image-properties",
    "title": "Introduction to AOP Public Datasets in Google Earth Engine (GEE)",
    "section": "",
    "text": "Next let’s take a look at the Image Properties.\n// look at the image properties\nvar clbj2021_refl_properties = refl001_CLBJ_2021.toDictionary()\nprint('CLBJ 2021 Directional Reflectance Properties:', clbj2021_refl_properties)\nLook in the Console for the properties, you can expand by clicking on the arrow to the left of the Object (438 properties). Here you can see some metadata about this image. Scroll down and you’ll get to a number of properties starting with WL_FWHM_B###. These are the WaveLength (WL) and Full Width Half Max (FWHM) values, in nanometers, corresponding to each band (Bands 001 - 426). You may wish to refer to this wavelength information to determine which bands you wish to display, eg. if you want to show a false color image instead of a true color (RGB) image. For a full description of what each of the Image Properties mean, you can look at the IMAGE PROPERTIES tab as explained in the previous section, or find it in the Earth Engine Data Catalog.",
    "crumbs": [
      "Tutorials",
      "1 Introduction to NEON AOP GEE Datasets"
    ]
  },
  {
    "objectID": "tutorials/01_intro_to_neon_aop_gee_datasets.html#determine-release-tag-information",
    "href": "tutorials/01_intro_to_neon_aop_gee_datasets.html#determine-release-tag-information",
    "title": "Introduction to AOP Public Datasets in Google Earth Engine (GEE)",
    "section": "",
    "text": "When working with NEON data, whether downloaded from the Data Portal or on GEE, we always recommend checking whether the data are Provisional or Released, and the release tag of the data. On GEE, this information is included in the image properties PROVISIONAL_RELEASED and RELEASE_YEAR. If the data is released, the property RELEASE_YEAR will display the year of the release. The code chunk below shows how to display the release information for the CLBJ 2021 directional reflectance data.\n// determine the release information for this image\nvar clbj2021_release_status = clbj2021_refl_properties.select(['PROVISIONAL_RELEASED']);\nprint('CLBJ 2021 Directional Reflectance Release Status:', clbj2021_release_status)\n\nvar clbj2021_release_year = clbj2021_refl_properties.select(['RELEASE_YEAR']);\nprint('CLBJ 2021 Directional Reflectance Release Year:', clbj2021_release_year)\nIn this example, the data is part of RELEASE-2024.\nFor more information on NEON releases, refer to the NEON Data Product Revisions and Releases page. There is a short period each year in January where AOP data on the NEON Data Portal may be in flux in preparation for an upcoming data release (typically end of January). GEE datasets are planned to be kept up to date with the current release, however there may be a lag period between the annual release and data updates on GEE. Data on GEE should be updated to match the current release by the end of February each year. For current information around the release status and data quality issue notices, you can follow NEON Data Notifications.",
    "crumbs": [
      "Tutorials",
      "1 Introduction to NEON AOP GEE Datasets"
    ]
  },
  {
    "objectID": "tutorials/01_intro_to_neon_aop_gee_datasets.html#plot-a-true-color-image",
    "href": "tutorials/01_intro_to_neon_aop_gee_datasets.html#plot-a-true-color-image",
    "title": "Introduction to AOP Public Datasets in Google Earth Engine (GEE)",
    "section": "",
    "text": "Finally, let’s plot a true color image (red-green-blue or RGB composite) of the reflectance data that we’ve read into the variable refl001_CBLJ_2021. To do this, first we pull out the RGB bands, set visualization parameters, center the map over the site, and then add the map using Map.addLayer. There are a couple ways you can center the Map to the location you want. One is to use Map.centerObject and you can provide the image you want to center; otherwise you can specify the latitude and longitude, shown commented-out in the code chunk below.\n// pull out the red, green, and blue bands\nvar refl001_CLBJ_2021_RGB = refl001_CLBJ_2021.select(['B053', 'B035', 'B019']);\n\n// set visualization parameters\nvar refl_rgb_vis = {min: 0, max: 1260, gamma: 0.8};\n\n// use centerObject to center on the reflectance data, 13 is the zoom level\nMap.centerObject(refl001_CLBJ_2021, 13)\n\n// alternatively you could specify the lat / lon of the site, set zoom to 13\n// you can find the field site lat/lon here https://www.neonscience.org/field-sites/clbj\n// Map.setCenter(-97.57, 33.40, 13);\n\n// add this RGB layer to the Map and give it a title\nMap.addLayer(refl001_CLBJ_2021_RGB, refl_rgb_vis, 'CLBJ 2021 Directional Reflectance RGB');\nWhen you run the code you should now see the true color image on the map! You can zoom in and out and explore some of the other interactive options on your own.",
    "crumbs": [
      "Tutorials",
      "1 Introduction to NEON AOP GEE Datasets"
    ]
  },
  {
    "objectID": "tutorials/01_intro_to_neon_aop_gee_datasets.html#compare-directional-and-bidirectional-reflectance",
    "href": "tutorials/01_intro_to_neon_aop_gee_datasets.html#compare-directional-and-bidirectional-reflectance",
    "title": "Introduction to AOP Public Datasets in Google Earth Engine (GEE)",
    "section": "",
    "text": "Lastly, let’s also look at a bidirectional data product at the same site, and you can explore the differences between the directional and bidirectional reflectance. We will also display the release information for this data.\n// read in a bidirectional reflectance image at the NEON site CLBJ in 2022\nvar refl002_CLBJ_2022 = refl002\n  .filterDate('2022-01-01', '2022-12-31') // filter by date - 2022\n  .filterMetadata('NEON_SITE', 'equals', 'CLBJ') // filter by site\n  .first(); // select the first one to pull out a single image\n\n// read the properties into a variable\nvar clbj2022_refl_properties = refl002_CLBJ_2022.toDictionary()\n\n// determine the release information for this BRDF-corrected image\nvar clbj2022_release_status = clbj2022_refl_properties.select(['PROVISIONAL_RELEASED']);\nprint('CLBJ 2022 Bidirectional Reflectance Release Status:', clbj2022_release_status)\n\n// if you try to read in the release year, it will throw an error\n// since this data product is still PROVISIONAL, there is no release year\n// comment out these lines below to remove\nvar clbj2022_release_year = clbj2022_refl_properties.select(['RELEASE_YEAR']);\nprint('CLBJ 2022 Bidirectional Reflectance Release Year:', clbj2022_release_year)\n  \n// pull out the red, green, and blue bands\nvar refl002_CLBJ_2022_RGB = refl002_CLBJ_2022.select(['B053', 'B035', 'B019']);\n\n// add this RGB layer to the Map and give it a title\nMap.addLayer(refl002_CLBJ_2022_RGB, refl_rgb_vis, 'CLBJ 2022 Bidirectional Reflectance RGB');\n\n  \n\nIf your code has any errors they will display in the Console tab in red. In this example, we tried to print out a property that does not exist because the data is Provisional, so there is no RELEASE_YEAR. You can comment out the lines of code starting with var clbj2022_release_year to prevent the error from displaying. If your code is not running as expected, errors displayed in the Console can be helpful for troubleshooting, as it will tell you how and where your code failed. Print statements throughout the code can also be helpful.\nNote that bidirectional reflectance data will remain provisional in 2025, since it is a new data product (as of 2024), and is planned to be incorporated into RELEASE-2026.\nYou can toggle between the two layers by selecting the “Layers” tab in the upper right corner of the Map window. Check and uncheck the two layers (2021 and 2022) to see the differences. You can also use the slider to the right of the layer name to make one layer partially transparent. What observations can you make about these two datasets?\n\n  \n\nThe BRDF and topographic corrections typically visibly improve striping (or BRDF effects) between adjacent flightlines, as we can see with these datasets at CLBJ, where the 2022 bidirectional reflectance (left) looks much more seamless than the 2021 directional reflectance data (right), which has some visible vertical artifacts. For most NEON sites, the flight lines are oriented N-S so the stripes in the directional reflectance data will be vertical, but there are a few sites with slightly different flight plans.",
    "crumbs": [
      "Tutorials",
      "1 Introduction to NEON AOP GEE Datasets"
    ]
  },
  {
    "objectID": "tutorials/01_intro_to_neon_aop_gee_datasets.html#a-quick-recap",
    "href": "tutorials/01_intro_to_neon_aop_gee_datasets.html#a-quick-recap",
    "title": "Introduction to AOP Public Datasets in Google Earth Engine (GEE)",
    "section": "",
    "text": "You did it! You now have a basic understanding of the GEE Code Editor and its different components. You have also learned how to read a NEON AOP ImageCollection into a variable, import the variable into your session, and navigate through the ImageCollection Asset details to display information about the collection. You learned to read in an individual reflectance image, explore the image properties, and display a map of a true color image (RGB composite). And finally, you explored some of the differences between the directional and bidirectional (BRDF- and topographic corrected) reflectance data products at the site CLBJ.\nIt doesn’t seem like we’ve done much so far, but this is a already great achievement! With just a few lines of code, you can import an entire AOP hyperspectral dataset, which in most other coding environments, is more involved. One of the major challenges to working with AOP reflectance data is its large data volume, which typically requires high-performance computing environments to read in the data, visualize, and analyze it. There are also limited open-source tools for working with hyperspectral data; many of the established software suites require proprietary (and often expensive) licenses. In this lesson, with minimal code, we have loaded spectral, lidar, and camera data covering an entire AOP site, and are ready to start exploring and analyzing the data in a free geospatial cloud-computing platform.",
    "crumbs": [
      "Tutorials",
      "1 Introduction to NEON AOP GEE Datasets"
    ]
  },
  {
    "objectID": "tutorials/01_intro_to_neon_aop_gee_datasets.html#get-lesson-code",
    "href": "tutorials/01_intro_to_neon_aop_gee_datasets.html#get-lesson-code",
    "title": "Introduction to AOP Public Datasets in Google Earth Engine (GEE)",
    "section": "",
    "text": "Into to AOP GEE Image Collections",
    "crumbs": [
      "Tutorials",
      "1 Introduction to NEON AOP GEE Datasets"
    ]
  }
]